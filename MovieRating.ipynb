{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import nltk\n",
    "import math\n",
    "from collections import defaultdict,Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 2)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('datasets/Train/Train.csv')\n",
    "train = np.array(df)\n",
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000,)\n"
     ]
    }
   ],
   "source": [
    "print(train[:,0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "allReviews = train[:,0]\n",
    "allRatings = train[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'(?<!\\S)[A-Za-z]+(?!\\S)|(?<!\\S)[A-Za-z]+(?=:(?!\\S))')\n",
    "en_stopwords = set(stopwords.words('english'))\n",
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCleanedReview(review):\n",
    "    review = review.lower()\n",
    "    review = review.replace('<br /><br />',' ')\n",
    "    \n",
    "    #Tokenize\n",
    "    tokens = tokenizer.tokenize(review)\n",
    "    #Remove Stopwords\n",
    "    new_tokens = [token for token in tokens if token not in en_stopwords]\n",
    "    #Stemmization\n",
    "    stemmed_tokens = [ps.stem(token) for token in new_tokens]\n",
    "    \n",
    "    cleaned_review = ' '.join(stemmed_tokens)\n",
    "    \n",
    "    return cleaned_review\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "efw wef ewf e fe fewwer frgreger rgr egerg reger g reer ger ger\n"
     ]
    }
   ],
   "source": [
    "print(getCleanedReview('efwe wef ewf e  fe fewwer frgreger  rgr egerg reger g reer ger ger'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning(allReviews):\n",
    "    count=1\n",
    "    cleaned_reviews = []\n",
    "    for review in allReviews:\n",
    "        review = str(review)\n",
    "        cleaned_reviews.append(getCleanedReview(review))\n",
    "    return cleaned_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_reviews = cleaning(allReviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_reviews = np.array(cleaned_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000\n"
     ]
    }
   ],
   "source": [
    "print(cleaned_reviews.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'head'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-39b23476356c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcleaned_reviews\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'head'"
     ]
    }
   ],
   "source": [
    "# cleaned_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pos' 'pos' 'pos' 'pos' 'pos' 'pos' 'neg' 'neg' 'pos' 'pos' 'neg' 'pos'\n",
      " 'pos' 'neg' 'pos' 'pos' 'pos' 'neg' 'pos' 'pos' 'neg' 'pos' 'pos' 'neg'\n",
      " 'pos' 'pos' 'pos' 'neg' 'pos' 'pos' 'neg' 'pos' 'neg' 'pos' 'neg' 'neg'\n",
      " 'neg' 'neg' 'neg' 'neg' 'pos' 'pos' 'neg' 'pos' 'neg' 'pos' 'neg' 'neg'\n",
      " 'neg' 'pos' 'neg' 'neg' 'neg' 'pos' 'neg' 'pos' 'pos' 'neg' 'neg' 'pos'\n",
      " 'neg' 'pos' 'neg' 'neg' 'neg' 'pos' 'pos' 'neg' 'pos' 'pos' 'pos' 'neg'\n",
      " 'neg' 'pos' 'pos' 'pos' 'pos' 'pos' 'pos' 'pos' 'neg' 'neg' 'neg' 'neg'\n",
      " 'neg' 'pos' 'neg' 'neg' 'pos' 'pos' 'pos' 'pos' 'neg' 'pos' 'neg' 'pos'\n",
      " 'pos' 'neg' 'neg' 'neg' 'neg' 'neg' 'neg' 'neg' 'neg' 'neg' 'pos' 'pos'\n",
      " 'pos' 'neg' 'pos' 'pos' 'neg' 'neg' 'neg' 'neg' 'pos' 'pos' 'neg' 'pos'\n",
      " 'pos' 'pos' 'pos' 'pos' 'pos' 'pos' 'neg' 'neg' 'pos' 'neg' 'pos' 'neg'\n",
      " 'neg' 'pos' 'neg' 'pos' 'pos' 'pos' 'neg' 'neg' 'pos' 'neg' 'neg' 'pos'\n",
      " 'neg' 'pos' 'neg' 'pos' 'pos' 'neg' 'pos' 'neg' 'neg' 'neg' 'pos' 'pos'\n",
      " 'neg' 'neg' 'neg' 'neg' 'neg' 'pos' 'pos' 'neg' 'neg' 'pos' 'neg' 'neg'\n",
      " 'pos' 'pos' 'neg' 'pos' 'neg' 'neg' 'neg' 'neg' 'pos' 'neg' 'neg' 'neg'\n",
      " 'pos' 'pos' 'pos' 'neg' 'pos' 'pos' 'neg' 'neg' 'neg' 'neg' 'pos' 'pos'\n",
      " 'pos' 'pos' 'neg' 'pos' 'pos' 'neg' 'neg' 'pos' 'neg' 'neg' 'neg' 'neg'\n",
      " 'pos' 'pos' 'neg' 'neg' 'pos' 'pos' 'neg' 'neg' 'pos' 'pos' 'pos' 'pos'\n",
      " 'neg' 'pos' 'pos' 'neg' 'pos' 'pos' 'neg' 'pos' 'neg' 'pos' 'neg' 'neg'\n",
      " 'pos' 'neg' 'pos' 'neg' 'pos' 'neg' 'neg' 'neg' 'neg' 'neg' 'pos' 'neg'\n",
      " 'neg' 'neg' 'pos' 'neg' 'neg' 'pos' 'neg' 'pos' 'neg' 'neg' 'neg' 'pos'\n",
      " 'pos' 'neg' 'pos' 'neg' 'neg' 'pos' 'pos' 'neg' 'neg' 'pos' 'pos' 'neg'\n",
      " 'pos' 'pos' 'neg' 'pos' 'pos' 'neg' 'pos' 'pos' 'neg' 'neg' 'pos' 'pos'\n",
      " 'neg' 'neg' 'pos' 'pos' 'neg' 'neg' 'pos' 'neg' 'neg' 'pos' 'pos' 'neg'\n",
      " 'neg' 'neg' 'neg' 'neg' 'neg' 'neg' 'pos' 'pos' 'neg' 'neg' 'pos' 'neg'\n",
      " 'neg' 'neg' 'neg' 'neg' 'neg' 'pos' 'neg' 'pos' 'pos' 'pos' 'neg' 'neg'\n",
      " 'neg' 'pos' 'pos' 'neg' 'pos' 'neg' 'pos' 'neg' 'pos' 'pos' 'neg' 'pos'\n",
      " 'neg' 'pos' 'neg' 'pos' 'pos' 'pos' 'pos' 'pos' 'pos' 'pos' 'pos' 'pos'\n",
      " 'neg' 'neg' 'neg' 'neg' 'pos' 'pos' 'pos' 'neg' 'pos' 'neg' 'neg' 'pos'\n",
      " 'pos' 'pos' 'pos' 'neg' 'neg' 'neg' 'neg' 'neg' 'pos' 'neg' 'neg' 'neg'\n",
      " 'pos' 'pos' 'neg' 'pos' 'pos' 'pos' 'pos' 'pos' 'neg' 'pos' 'neg' 'pos'\n",
      " 'neg' 'neg' 'pos' 'pos' 'pos' 'pos' 'pos' 'neg' 'neg' 'neg' 'pos' 'pos'\n",
      " 'pos' 'neg' 'neg' 'pos' 'pos' 'neg' 'neg' 'pos' 'neg' 'pos' 'pos' 'pos'\n",
      " 'neg' 'neg' 'neg' 'pos' 'neg' 'neg' 'neg' 'pos' 'pos' 'neg' 'pos' 'neg'\n",
      " 'neg' 'pos' 'neg' 'neg' 'neg' 'pos' 'pos' 'pos' 'neg' 'pos' 'neg' 'pos'\n",
      " 'neg' 'pos' 'pos' 'neg' 'neg' 'pos' 'neg' 'pos' 'neg' 'pos' 'pos' 'pos'\n",
      " 'neg' 'pos' 'neg' 'pos' 'neg' 'pos' 'neg' 'pos' 'neg' 'pos' 'neg' 'neg'\n",
      " 'neg' 'pos' 'pos' 'neg' 'neg' 'pos' 'neg' 'pos' 'pos' 'pos' 'neg' 'neg'\n",
      " 'pos' 'neg' 'pos' 'pos' 'pos' 'neg' 'neg' 'neg' 'pos' 'pos' 'neg' 'neg'\n",
      " 'neg' 'neg' 'pos' 'neg' 'neg' 'pos' 'neg' 'neg' 'pos' 'pos' 'neg' 'neg'\n",
      " 'pos' 'pos' 'pos' 'pos' 'neg' 'neg' 'pos' 'pos' 'neg' 'neg' 'neg' 'neg'\n",
      " 'neg' 'pos' 'pos' 'neg' 'pos' 'pos' 'pos' 'neg' 'neg' 'neg' 'pos' 'neg'\n",
      " 'neg' 'pos' 'neg' 'neg' 'neg' 'pos' 'neg' 'pos' 'neg' 'neg' 'pos' 'pos'\n",
      " 'pos' 'pos' 'neg' 'pos' 'neg' 'neg' 'pos' 'pos' 'neg' 'neg' 'neg' 'neg'\n",
      " 'pos' 'neg' 'pos' 'neg' 'pos' 'neg' 'neg' 'neg' 'neg' 'neg' 'pos' 'neg'\n",
      " 'pos' 'pos' 'neg' 'neg' 'neg' 'neg' 'neg' 'neg' 'neg' 'pos' 'neg' 'neg'\n",
      " 'neg' 'neg' 'neg' 'pos' 'pos' 'neg' 'pos' 'neg' 'pos' 'neg' 'pos' 'pos'\n",
      " 'neg' 'neg' 'neg' 'neg' 'pos' 'neg' 'neg' 'pos' 'neg' 'pos' 'neg' 'pos'\n",
      " 'neg' 'neg' 'neg' 'pos' 'pos' 'neg' 'neg' 'pos' 'neg' 'neg' 'neg' 'neg'\n",
      " 'pos' 'pos' 'neg' 'neg' 'neg' 'pos' 'pos' 'neg' 'neg' 'pos' 'pos' 'pos'\n",
      " 'pos' 'pos' 'neg' 'neg' 'neg' 'neg' 'pos' 'neg' 'neg' 'neg' 'pos' 'neg'\n",
      " 'neg' 'pos' 'neg' 'pos' 'neg' 'neg' 'pos' 'pos' 'pos' 'pos' 'neg' 'pos'\n",
      " 'neg' 'pos' 'pos' 'neg' 'pos' 'pos' 'neg' 'pos' 'neg' 'pos' 'pos' 'pos'\n",
      " 'neg' 'pos' 'pos' 'pos' 'pos' 'neg' 'pos' 'neg' 'neg' 'neg' 'neg' 'pos'\n",
      " 'neg' 'neg' 'pos' 'neg' 'pos' 'pos' 'pos' 'neg' 'neg' 'neg' 'pos' 'neg'\n",
      " 'neg' 'pos' 'neg' 'pos' 'neg' 'pos' 'pos' 'neg' 'neg' 'pos' 'pos' 'pos'\n",
      " 'pos' 'pos' 'pos' 'pos' 'pos' 'pos' 'pos' 'neg' 'pos' 'pos' 'pos' 'pos'\n",
      " 'pos' 'neg' 'pos' 'pos' 'pos' 'pos' 'neg' 'neg' 'neg' 'pos' 'neg' 'neg'\n",
      " 'pos' 'pos' 'pos' 'pos' 'pos' 'pos' 'pos' 'pos' 'neg' 'pos' 'neg' 'pos'\n",
      " 'neg' 'pos' 'neg' 'neg' 'neg' 'pos' 'neg' 'pos' 'pos' 'pos' 'pos' 'neg'\n",
      " 'pos' 'neg' 'neg' 'pos' 'neg' 'pos' 'neg' 'neg' 'pos' 'neg' 'pos' 'neg'\n",
      " 'pos' 'pos' 'neg' 'neg' 'pos' 'pos' 'pos' 'neg' 'neg' 'pos' 'pos' 'pos'\n",
      " 'pos' 'neg' 'pos' 'pos' 'neg' 'pos' 'neg' 'pos' 'neg' 'pos' 'neg' 'pos'\n",
      " 'neg' 'pos' 'pos' 'neg' 'pos' 'pos' 'neg' 'pos' 'neg' 'pos' 'neg' 'pos'\n",
      " 'pos' 'pos' 'neg' 'neg' 'pos' 'neg' 'neg' 'pos' 'pos' 'pos' 'neg' 'pos'\n",
      " 'neg' 'neg' 'neg' 'neg' 'neg' 'neg' 'neg' 'pos' 'pos' 'pos' 'neg' 'neg'\n",
      " 'neg' 'pos' 'neg' 'neg' 'pos' 'pos' 'pos' 'neg' 'neg' 'neg' 'neg' 'pos'\n",
      " 'neg' 'neg' 'neg' 'pos' 'neg' 'pos' 'pos' 'neg' 'pos' 'pos' 'neg' 'neg'\n",
      " 'pos' 'neg' 'neg' 'neg' 'neg' 'neg' 'neg' 'neg' 'neg' 'neg' 'pos' 'pos'\n",
      " 'pos' 'pos' 'pos' 'pos' 'pos' 'neg' 'neg' 'neg' 'neg' 'neg' 'pos' 'neg'\n",
      " 'pos' 'neg' 'pos' 'neg' 'pos' 'neg' 'pos' 'pos' 'pos' 'pos' 'pos' 'neg'\n",
      " 'pos' 'neg' 'neg' 'pos' 'pos' 'pos' 'pos' 'neg' 'neg' 'neg' 'pos' 'neg'\n",
      " 'pos' 'neg' 'neg' 'neg' 'pos' 'neg' 'neg' 'neg' 'neg' 'pos' 'pos' 'pos'\n",
      " 'neg' 'pos' 'neg' 'pos' 'pos' 'pos' 'pos' 'pos' 'pos' 'neg' 'neg' 'neg'\n",
      " 'neg' 'neg' 'pos' 'pos' 'pos' 'neg' 'neg' 'pos' 'pos' 'neg' 'neg' 'neg'\n",
      " 'neg' 'pos' 'pos' 'neg' 'neg' 'neg' 'pos' 'neg' 'neg' 'neg' 'neg' 'neg'\n",
      " 'neg' 'pos' 'pos' 'pos' 'pos' 'neg' 'neg' 'pos' 'neg' 'neg' 'pos' 'neg'\n",
      " 'pos' 'neg' 'pos' 'pos' 'neg' 'pos' 'pos' 'neg' 'pos' 'neg' 'neg' 'neg'\n",
      " 'pos' 'neg' 'pos' 'pos' 'neg' 'pos' 'neg' 'neg' 'neg' 'pos' 'neg' 'pos'\n",
      " 'neg' 'pos' 'pos' 'neg' 'neg' 'pos' 'neg' 'pos' 'pos' 'neg' 'neg' 'neg'\n",
      " 'neg' 'neg' 'neg' 'neg' 'pos' 'neg' 'pos' 'pos' 'neg' 'neg' 'neg' 'neg'\n",
      " 'neg' 'neg' 'neg' 'pos' 'neg' 'pos' 'neg' 'neg' 'pos' 'neg' 'pos' 'pos'\n",
      " 'neg' 'neg' 'neg' 'pos' 'neg' 'neg' 'pos' 'neg' 'pos' 'neg' 'pos' 'pos'\n",
      " 'pos' 'pos' 'pos' 'neg']\n"
     ]
    }
   ],
   "source": [
    "print(allRatings[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(cleaned_reviews, allRatings):\n",
    "    n_class_items = {}\n",
    "    log_class_priors = {}\n",
    "    word_counts = {}\n",
    "    vocab = set()\n",
    "    \n",
    "    n = cleaned_reviews.shape[0]\n",
    "    # For positive Statements\n",
    "    pos_data = cleaned_reviews[np.where(allRatings=='pos')]\n",
    "    # For negative Statements\n",
    "    neg_data = cleaned_reviews[np.where(allRatings=='neg')]\n",
    "    \n",
    "    n_class_items['pos'] = pos_data.shape[0]\n",
    "    n_class_items['neg'] = neg_data.shape[0]\n",
    "    \n",
    "    log_class_priors['pos'] = math.log(n_class_items['pos']/n)\n",
    "    log_class_priors['neg'] = math.log(n_class_items['neg']/n)\n",
    "    \n",
    "    word_counts['pos'] = defaultdict(lambda: 0)\n",
    "    word_counts['neg'] = defaultdict(lambda: 0)\n",
    "    \n",
    "    for text in pos_data:\n",
    "        text = text.split()\n",
    "        counts = Counter(text)\n",
    "        for word, count in counts.items():\n",
    "            vocab.add(word)\n",
    "            word_counts['pos'][word] += count\n",
    "    \n",
    "    for text in neg_data:\n",
    "        text = text.split()\n",
    "        counts = Counter(text)\n",
    "        for word, count in counts.items():\n",
    "            vocab.add(word)\n",
    "            word_counts['neg'][word] += count\n",
    "    \n",
    "    return n_class_items, log_class_priors, word_counts, vocab\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(test, n_clas_items, log_class_priors, word_counts, vocab):\n",
    "    result = []\n",
    "    for text in test:\n",
    "        class_scores = {c: log_class_priors[c] for c in ['pos','neg']}\n",
    "        words = (getCleanedReview(text).split())\n",
    "        \n",
    "        for word in words:\n",
    "            # pos\n",
    "            num = word_counts['pos'][word]+1\n",
    "            denom = n_class_items['pos']+ len(vocab)\n",
    "            log_w_pos = math.log(num/denom)\n",
    "            class_scores['pos'] += log_w_pos\n",
    "            \n",
    "            #neg\n",
    "            num = word_counts['neg'][word]+1\n",
    "            denom = n_class_items['neg']+ len(vocab)\n",
    "            log_w_pos = math.log(num/denom)\n",
    "            class_scores['neg'] += log_w_pos\n",
    "        \n",
    "        \n",
    "        result.append(max(class_scores,key = class_scores.get))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 1)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('datasets/Test/Test.csv')\n",
    "test = np.array(df)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_class_items, log_class_priors, word_counts, vocab = fit(cleaned_reviews, allRatings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-764f8da155aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array"
     ]
    }
   ],
   "source": [
    "test = test[:,0]\n",
    "print(test.shape)\n",
    "\n",
    "print[test[0].shape]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = predict(test,n_class_items, log_class_priors, word_counts, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('datasets/Test/output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv",
   "language": "python",
   "name": "myvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
